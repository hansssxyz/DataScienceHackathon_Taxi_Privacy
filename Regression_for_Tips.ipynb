{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5d3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import decomposition\n",
    "import pandas as pd\n",
    "\n",
    "# Pickup_Time_(Hours)\n",
    "# Pickup_X_Coordinate\n",
    "# Pickup_Y_Coordinate\n",
    "# Dropoff_X_Coordinate\n",
    "# Dropoff_Y_Coordinate\n",
    "# Passenger_Number\n",
    "# Tip_Amount\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('./regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7901154",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pickup_Time_Hours = df[\"Pickup_Time_(Hours)\"].to_list()\n",
    "min_pt              = min(Pickup_Time_Hours)\n",
    "max_pt              = max(Pickup_Time_Hours)\n",
    "diff_pt             = max_pt - min_pt\n",
    "\n",
    "Pickup_X_Coordinate = df[\"Pickup_X_Coordinate\"].to_list()\n",
    "min_pxc             = min(Pickup_X_Coordinate)\n",
    "max_pxc             = max(Pickup_X_Coordinate)\n",
    "diff_pxc            = max_pxc - min_pxc\n",
    "\n",
    "Pickup_Y_Coordinate = df[\"Pickup_Y_Coordinate\"].to_list()\n",
    "min_pyc             = min(Pickup_Y_Coordinate)\n",
    "max_pyc             = max(Pickup_Y_Coordinate)\n",
    "diff_pyc            = max_pyc - min_pyc\n",
    "\n",
    "Dropoff_X_Coordinate = df[\"Dropoff_X_Coordinate\"].to_list()\n",
    "min_dxc              = min(Dropoff_X_Coordinate)\n",
    "max_dxc              = max(Dropoff_X_Coordinate)\n",
    "diff_dxc             = max_dxc - min_dxc\n",
    "\n",
    "Dropoff_Y_Coordinate = df[\"Dropoff_Y_Coordinate\"].to_list()\n",
    "min_dyc              = min(Dropoff_Y_Coordinate)\n",
    "max_dyc              = max(Dropoff_Y_Coordinate)\n",
    "diff_dyc             = max_dyc - min_dyc\n",
    "\n",
    "Passenger_Number = df[\"Passenger_Number\"].to_list()\n",
    "min_pn           = min(Passenger_Number)\n",
    "max_pn           = max(Passenger_Number)\n",
    "diff_pn          = max_pn - min_pn\n",
    "\n",
    "Tip_Amount = df[\"Tip_Amount\"].to_list()\n",
    "min_ta              = min(Tip_Amount)\n",
    "max_ta              = max(Tip_Amount)\n",
    "diff_ta          = max_ta - min_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f330d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pickup_Time_Hours = [(pt-min_pt)/diff_pt * 10 for pt in Pickup_Time_Hours]\n",
    "Pickup_X_Coordinate = [(pt-min_pxc)/diff_pxc * 10 for pt in Pickup_X_Coordinate]\n",
    "Pickup_Y_Coordinate = [(pt-min_pyc)/diff_pyc * 10 for pt in Pickup_Y_Coordinate]\n",
    "Dropoff_X_Coordinate = [(pt-min_dxc)/diff_dxc * 10 for pt in Dropoff_X_Coordinate]\n",
    "Dropoff_Y_Coordinate = [(pt-min_dyc)/diff_dyc * 10 for pt in Dropoff_Y_Coordinate]\n",
    "Passenger_Number = [(pt-min_pn)/diff_pn * 10 for pt in Passenger_Number]\n",
    "Tip_Amount = [(pt-min_ta)/diff_ta * 10 for pt in Tip_Amount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2587a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pickup_Time_(Hours)\"] = Pickup_Time_Hours\n",
    "df[\"Pickup_X_Coordinate\"] = Pickup_X_Coordinate\n",
    "df[\"Pickup_Y_Coordinate\"] = Pickup_Y_Coordinate\n",
    "df[\"Dropoff_X_Coordinate\"] = Dropoff_X_Coordinate\n",
    "df[\"Dropoff_Y_Coordinate\"] = Dropoff_Y_Coordinate\n",
    "df[\"Passenger_Number\"] = Passenger_Number\n",
    "df[\"Tip_Amount\"] = Tip_Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5c16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df.drop([\"Tip_Amount\"], axis=1)\n",
    "y = df[\"Tip_Amount\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654c116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.8310951373293983\n",
      "The error rate is:  8.310951373293983 %\n"
     ]
    }
   ],
   "source": [
    "# Convert the data into DMatrix format, which is an optimized data structure for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set the hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 5,\n",
    "    'alpha': 0.1,\n",
    "    'lambda': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print(\"The error rate is: \", mse /10 *100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94817631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Manhattan distance error is: 3.151675549773707\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df[\"Tip_Amount\"]\n",
    "y1 = df[\"Dropoff_X_Coordinate\"]\n",
    "y2 = df[\"Dropoff_Y_Coordinate\"]\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2)\n",
    "_, _, y2_train, y2_test = train_test_split(X, y2, test_size=0.2)\n",
    "\n",
    "# Convert the data into DMatrix format, which is an optimized data structure for XGBoost\n",
    "dtrain1 = xgb.DMatrix(X_train, label=y1_train)\n",
    "dtest1 = xgb.DMatrix(X_test, label=y1_test)\n",
    "dtrain2 = xgb.DMatrix(X_train, label=y2_train)\n",
    "dtest2 = xgb.DMatrix(X_test, label=y2_test)\n",
    "\n",
    "# Set the hyperparameters for the XGBoost model\n",
    "params1 = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 5,\n",
    "    'alpha': 0.1,\n",
    "    'lambda': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 5,\n",
    "    'alpha': 0.1,\n",
    "    'lambda': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# Train the XGBoost models\n",
    "model1 = xgb.train(params1, dtrain1, num_boost_round=100)\n",
    "model2 = xgb.train(params2, dtrain2, num_boost_round=100)\n",
    "\n",
    "# Predict on the test set\n",
    "y1_pred = model1.predict(dtest1)\n",
    "y2_pred = model2.predict(dtest2)\n",
    "\n",
    "# Calculate the mean squared errors\n",
    "res = 0\n",
    "for i in range(len(y1_pred)):\n",
    "    res += abs(y1_test.tolist()[i]-y1_pred.tolist()[i]) + abs(y2_test.tolist()[i]-y2_pred.tolist()[i])\n",
    "error = res / len(y1_pred)\n",
    "print('Overall Manhattan distance error is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac48fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=10\n",
    "\n",
    "regression_array=[]\n",
    "with open('regression.csv', newline='') as pre:\n",
    "    reader = csv.reader(pre, delimiter=',')\n",
    "    line = 0\n",
    "    for row in reader:\n",
    "        if line == 0:\n",
    "            data_rep = row\n",
    "        else:\n",
    "            regression_array.append(row)\n",
    "        line += 1\n",
    "\n",
    "num_data=len(regression_array)\n",
    "num_col=len(regression_array[0])\n",
    "\n",
    "dif=np.zeros(num_col)\n",
    "Min=np.zeros(num_col)\n",
    "Max=np.zeros(num_col)\n",
    "for i in range(num_data):\n",
    "    if (i==0):\n",
    "        for j in range(num_col):\n",
    "            Max[j]=regression_array[i][j]\n",
    "            Min[j]=regression_array[i][j]\n",
    "    else:\n",
    "        for j in range(num_col):\n",
    "            if (float(regression_array[i][j])>Max[j]):\n",
    "                Max[j]=regression_array[i][j]\n",
    "            if (float(regression_array[i][j])<Min[j]):\n",
    "                Min[j]=regression_array[i][j]\n",
    "dif=Max-Min\n",
    "randomV=[]\n",
    "for i in range(num_col):\n",
    "    randomV.append(laplace_draw(0,dif[i]/epsilon,Min[i],Max[i],num_data))\n",
    "\n",
    "for i in range(num_data):\n",
    "    for j in range(num_col):\n",
    "        regression_array[i][j]=max(0,float(regression_array[i][j])+randomV[j][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
